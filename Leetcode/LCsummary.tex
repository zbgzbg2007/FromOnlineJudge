\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{color}
\begin{document}
\title{
{Summary for LC alg problems}
}
\author{B. Z.}
\date{}
\maketitle
\begin{abstract}
I will try to summarize the methods, the code will not be included in this file.
\end{abstract}

\paragraph{14}
For each leter, we check all the strings to see if it is contained by all strings. If we find it is not in one string, or we  
reach the end of one string, we output the prefix ending at the current index. The running time is $(n*m)$ where $n$ is the 
length of the longest common prefix and $m$ is the number of strings.

\paragraph{139}
This can be solved by dynamic programming. Let $dp[i]$ denote if $s[:i]$ can be obtained by the words in the dictionary. We 
store all the words in a set so that we can search them in $O(1)$ time. We try index $i$ from 1 to $len(s)$ and for each index 
we want to know if $dp[i]$ is true or not. If it is true, then there is another index $j < i$ such that $dp[j]$ is true and 
$s[j:i]$ can be found in the dictionary. The running time is $O(n^2 + m)$ where $n$ is the length of the input word $s$ and 
$m$ is the length of the dictionary.

\paragraph{402}
We go through the string from left to right and maitain a stack for the seen numbers. The numbers in the stack is in the 
increasing order. When the new number is smaller then the top of the stack, we pop out the numbers in the stack until the top
number is not bigger than the new number or we have already popped $k$ numbers. After this, if we still need to delete some 
numbers, we just continue popping from the stack. The numbers in the stack is the result string. 
This can be done in linear time.

\paragraph{456}
We solve the problem iteratively. We go through the list from right to left once and record the information in the following 
way. We use $s^*_3$ to store the maximum value of $s_3$ so far, that is for all the values 
we have seen, $s^*_3$ is the maximum value such that there is another value whose index is smaller than its.
We use a stack $l$ to store the candidates of $s_3$ so far, whose values are monotone and contains the $s_2$ for $s^*_3$.
Let $x$ be the next value we will check. If $x < s^*_3$, then $x$ could be $s_1$ and we already find a 
pattern and return true; otherwise we pop the values in $l$ until the top is not smaller than $x$. The largest popped value from
$l$ will become the new $s^*_3$ since all the poped values should be larger than $s^*_3$ (otherwise, if the smaller value is 
on the left of $s^*_3$, then we should find the pattern and if it is on the right of $s^*_3$ then it should be popped already) 
and we push $x$ into $l$, which will be the new $s_2$. This can be done in liear time.

\paragraph{459}
This problem can be solved in many ways. Here we show two menthods. Let $n$ be the length of the string $s$.
\begin{itemize}
\item The first method is to verify each substring of length $i$ for $1 \le i \le n/2$. Each verification needs $O(n)$ time,
so the running time is $O(n^2)$.
\item The second method is faster and simpler. 
\begin{itemize}
\item Algorithm. We concatenate two input strings to obtain $s'$, that is $s' = s + s$.
Then we delete the first and the last character to obtain $s^*$, that is $s^* = s'[1:-1]$. Now if we can find s in $s^*$,
return true, otherwise return false. The running time is $O(n)$. 
\item Proof. If $s$ consists of repeated substrings, then it is obvious that our algorithm outputs true. So we only need 
to prove that if our algorithm outputs true, then $s$ consists of repeated substrings. We can prove the correctness by 
induction. Assume all the indices are 0-based. Let $p$ be the smallest index starting from which we find the appearance of 
$s$ in $s^*$. Let $t = s[0:p]$. Then we know t is a prefix of $s$ and also a suffix of $s$. That is $s[p:2p] = 
t$ since $s$ matches $s^*$ starting from index $p$ and similarly $s[-p:] = t$. Continue this argument, we know that
$s[kp:(k+1)p] = t$ if $(k+1)p \le n$. If $n \% p == 0$, then this property shows $s$ consists of $n/p$ number of $t$'s 
and we are done. So assume $n \% p == a != 0$. Then we find that the substring $x = s[-a:]$ is also a prefix of $t$ and a 
suffix of $t$. Now we are in a case that seems familiar. So we repeat the above argument and then we find that either $t$ 
consists of repeated $x$ (if $p \% a == 0$) or there is another substring $y$ of $x$ that have the same property (if $p \% a
!= 0$). Note that the length of $y$ is smaller than $x$ and we can continue this argument until $p' \% a' == 0$. This is 
always possible since the endpoint is when $a' == 1$. This means all the prefix substrings consists of repeated strings of 
length $a'$, which is a contradiction since $a' != p$ and we should find $a'$ as the smallest index instead of $p$.
\end{itemize}

\paragraph{461}
We can first convert the two numbers into binary strings by bin or formatting string. For example, $'{0:08b}'.format(6)$ gives 
$'00000110'$ as output. Here, ${}$ places a variable into a string; $0$ takes the variable at argument position 0 
(the 0th argument to format); 
$:$ adds formatting options for this variable (otherwise it would represent decimal 6); 
$08$ formats the number to eight digits zero-padded on the left;
$b$ converts the number to its binary representation.
Another way to write this is $format(6, '08b')$. We use this instead of $bin$ function because the length of the two strings 
may be different.

\paragraph{463}
We count the boundary for each cell with 1. If the neighbor is 0 or the boundary of the grid, we add one to answer.
This can be done in $O(nm)$ time for $n$ and $m$ being the sizes of the grid.

\paragraph{466}
Let $S1 = s1 * n1$ and $S2 = s2 * n2$. We want to compute how many $s2$ we can find in $S1$ and then we know how many $S2$ can 
be found in $S1$. To save the time, we want to find the cyclical appearance of $s2$ in $S1$, that is, the indices in $s1$ that 
matching elements in $s2$ do not change any more. For example, $s2[0]$ always matches $s1[i]$ for some fixed $i$ and $s2[1]$ 
matches $s1[j]$ for some fixed $j$ where $i$ and $j$ do not change.
If we find these, then we do not need to match strings in the cyclical appearance. Then the matching can be seen as three parts:
before we find the cyclical appearance of $s2$, the cyclical appearance of $s2$ and the rest part that cannot form a cyclical 
appearance. 
We store the indices of $s1$ that successfully matches $s2[-1]$ in a list $repeat$ and store the number of $s1$ we have seen in 
a list $cnt$, that is $cnt[i]$ corresponds to the (0-based) number of $s1$ when we see $repeat[i]$. 
Now when we find a new value $repeat$ that appears in $repeat$ before, we know there is a cyclical appearance. 
Then we can compute the number of $s2$ in the three parts. The first part is the number of elements in $repeat$ before the 
cyclical appearance starts; the second part is the number of $s2$ in the cyclical appearance times the number of cycles; and 
the third part is the number of $repeat$ in the cyclical appearance that are in the rest $S1$. 
We can use $cnt$ to count the number of $s1$ we have used for the third part.

Let $n$ and $m$ be the length of $s1$ and $s2$. To compute the lists $repeat$ and $cnt$, we only need at most $2m+2$ number of 
$s1$. If there is no cyclical appearance in $2m+2$ number of $s1$'s, then there is no matching from $s2$ to repeatition of $s1$.
This is because we can always find the start of a cyclical appearance (which may not be $s2[0]$) in $m+1$ number of $s1$ if it 
exists. The reason is as follows.
Each time we try a new copy of $s1$, we have at least one element of $s2$ that is matched in this $s1$ copy.
Then for each copy of $s1$, we have a substring $x$ of $s2$ that are matched in this copy. 
Consider the first element in $x$. When this element repeats, we have a cyclical appearance.
There can be at most $m$ different elements as the start of $x$, so when wen try $m+1$ number of $s1$, we must either find the
start of the cyclical appearance, or there is no matching between $s2$ and any repeatitions of $s1$. 
Then in $2m+2$ number of $s1$, we must find that $s2[-1]$ is repeated in the cyclical appearnce.
So to find the cyclical appearance of $s2$, we only need at most $3m$ number of $s1$.
The real number of $s1$ we try is $\min \{ n1, 3m\}$, since $n1$ may be very small so that we do not need to find the cyclical 
appearance. 
The running time for this will be $O(mn)$ if $n1 > 3m$ and $O(nn1)$ if $n1 <= 3m$.

\paragraph{467}
We only need to record the length of the longest substring that ends with different letters. Since there are only lower letters 
in the inputs, we only need to record 26 numbers for each letter. We can maintain a starting index for current substring and 
update the lengths each time we see a new letter. The answer is the sum of all the lengths. The running time is linear. 



\paragraph{472}
This problem can be solved in different ways. The first is to use dynamic programming, which is similar to the problem 139.
The second way is to use Trie and search the word in the Trie tree. We only talk about the first method, since it is simple 
to write and analyze, and it is more efficient. The worse case running time for the second method can be $O(2^n)$ since 
each time we see an end of a short word, we need to decide if we should continue the current longer word (that is we follow 
the current subtree) or jump to the root of the tree and start again. So totally the running time could be exponential to the
length of the word. The first method is to try dynamic programming for each word to see if it could be decomposed into other 
words. We first sort the words according to their lengths in the increasing order for the longer word can only be decomposed 
into short words. For each word, we apply the same method as probem 139 to see if it could be obtained from previous words. 
After that, we add the current word into our dictionary set and continue. The totall running time will be $(n^2m)$ where $n$ 
is the max length of words, and $m$ is the number of words.

\paragraph{474}
This is similar to 0-1 knapsack problem. We could solve this by dynamic programming. Let $dp[k][i][j]$ denote the max number 
of strings we can obtain from the first $k$ strings and there are $i$ 0's and $j$ 1's left. Let $nums[k][0]$ and $nums[k][1]$ 
denote the number of 0's and 1's in the $k$th string.
Then we know $dp[k][i][j] = \max \{ dp[k][i][j], dp[k-1][i+nums[k][0]][j+nums[k][1]]+1 \}$ if $i+nums[k][0] \le m$ and 
$j+nums[k][1] \le n$. We can also simplify this by using a 2-dimensional list $dp[i][j]$ and then go through the $i$ and $j$ 
in the increasing order. The result is the maximum value in $dp$.
The running time is $O(mnl+N)$ where $l$ is the number of the strings and $N$ is the total length of
all strings.


\paragraph{480}
There are two ways to solve this problem. 
\begin{itemize}
\item The first is to maintain a sorted array for the current interval and each time we 
see a new element we add it into the sorted array by binary search and then remove the oldest element if needed. 
The complexity of the addition and removement operations are the key point for this method. If we use C++ and choose set
as the data structure, these operation can be done in $O(\log n)$ time (but we also need to maintain the iterator for the 
median since we need to find it for each interval and set does not provide binary search API), and the running time is 
$O(n\log k)$ for $n$ and $k$ being the length of the list and interval. If we choose list in Python, then the running time 
is $O(nk)$ since both of the operations need $O(k)$ time.

\item The second method is to maintain two heaps for the interval: one is max-heap for $k/2$ smaller elements and one is min-heap
for $k/2$ larger elements. We also need a hashmap or dictionary to record the elements that should be removed from the heaps and 
two integers to record the valid elemtns in the two heaps. These are needed because there could be some elements in the heaps
that are outside of the interval and we cannot remove all invalid elements when the interval moves. 
So when we pop the heaps, we need to make sure the element is valid or not. 
The running time for this is $O(n \log n)$ since the heap could contain $O(n)$ elements.
\end{itemize}

\paragraph{483}
This could be solved by binary search. Assume we know the representation of $n$ base $k$, that is we know the number of 
the 1's. Then we can use binary search to guess the correct $k$, that is just a geometric series of the same length as the
number of 1's. We know the length of 1's can be at most $O(\log n)$, and the binary search needs $O(\log n)$ time (two 
endpoints are 2 and $n+1$), so the total running time is $O(\log ^2 n)$.

\paragraph{498}
We can follow the rule to generate the answer. First we set a flag to represent the direction, and each time we go beyond the 
boundary, we move the index back. For the second half of the matrix, we need to move one index two steps back.

\paragraph{502}
This could be solved by heap. We can use two heaps $heap1$ and $heap2$: $heap1$ (max heap) storing the profits of the projects 
whose capital is less than our current capital $W$ and $heap2$ (min heap for capital) storing the capitals and profits whose
capital is more than $W$. Each time we choose the top of $heap1$ to add into our solution and then update $W$. 
Then we pop all possible projects from $heap2$ and push them to $heap1$. After $k$ times, the $W$ is the answer.
We could also just use one max heap (that is the same as $heap1$ above). We first construct an array whose elements are the tuple
(profit, capital) of all projects. And then we sort the array by capital. 
Now for each of the $k$ iterations, we only need to pop all possible projects in the array and then push them to the max heap. 
Since the array is sorted by capitals, we have all possible projects in our heap.
Note that the pop operation only needs $O(1)$ time for list.
The running time is $O(n \log n)$ where $n$ is the total number of projects. This is because for two heaps we push all of them 
into heaps, and for one heap we sort all the projects.

\paragraph{507}
Try every possible number in $[2, \sqrt num]$. If $i$ is a divisor, then subtract $i$ and $num/i$. 
Running time is $O(\sqrt n)$.

\paragraph{514}
We solve this by dynamic programming.
The state dp[i][j] is the minimum step to finish matching the first $i$ letter and the ring stops at the position $j$ and 
this position $j$ has the same letter as the $i$-th letter in the key. This can be obtained from dp[i-1][:] by trying the 
two direction rotation. To improve the running time a little bit, We use dictionary instead of list to store dp[i][j] and
we only store those position $j$ that has the matched letter for dp[i].
The running time is $O(n^3)$.

\paragraph{517}
This can be solved in a greedy way. 
First compute the target number of dresses: the final number of dresses in each machine should be the same, so it is just total number divided by number of machines. If not an integer, then impossible.
Start from beginning (the leftmost machine), for the current machine $i$, record the number of moves to make it have target number of dresses: if it has more than target, then move all the additional dresses from it to $i+1$; if less than target, then move all needed dresses from $i+1$ to it. 
Record this number of moves in $count$ array and update the number of dresses in machine $i+1$.
The result is the maximum in $count$.
The running time is $O(n)$.
This could work since each number in $count$ is a lower bound for the machine, which is feasible. (Can be proved by induction: the first $i$ machines have optimal moves and we do not need to worry about them.)
BFS could work, but the running time is too big since the number of states are very big.

\paragraph{521}
We do not need to consider subsequence, the candidate should be the entire string. Then the problem is simplified. If the length of the two strings are different, return the bigger length. Otherwise if the two strings are different, return 
the length of any one, othwerwise return -1. 

\paragraph{522}
Notice that the candidate should only be the entire string, not its proper subsequence.
This is because if the candidate has a proper subsequence satisfying the condition, the candidate string also satisfies the 
condition. So we only consider each entire string and check if it is subsequence of other strings. 
Before comparing strings, we sort the strings according to their lengths. Take care of the iter() funciton. 
The running time is $O(mn)$, where $n$ is the number of strings, and $m$ is the length of the longest string.



\paragraph{523}
For each index $i$, we first compute the sum from 0 to $i$ and then modulo $k$. We record this number $x_i$ for each index in a dict.
For current index $j$, we check $x_j$: if $x_j$ first appears at $i$ before and $j - i > 1$, then output True; or if $x_j == 0$ and $j > 0$, then output True.
The boundary case is $k = 0$, we need to check if there are two adjacent 0's.
This needs $O(n)$ time and $O(k)$ space.
 
\paragraph{524}
Sort the list into such that the list is decreasing in the length of the string and for the same length it is sorted in lexicographical order.
Then test each string in this order: if it is a substring of input string $s$ then output the current tested string.
This needs $O(nm + d \log d)$ time, where $n$ and $m$ are the length of input strings and $d$ is the size of the list.

\paragraph{525}
Preprocess the numbers: change 0 to -1.
Then the interval containing same numbers of 1 and -1 has sum 0.
Now loop the array and compute the sum from 0 to current index. 
We record the first index for each distinct sum value by a hash map.
When the sum appears again, we can find the target interval by the recored first index for that sum.
This runs in $O(n)$ time.

My first try is binary search on the length of the interval, but that does not work, since the result is not contiguous in the lengths. That is, if there is an interval of length $l$, then the subinterval of length $l-2$ may not be a feasible solution. Example: $000111111000$.


\paragraph{526}
Find all the possible numbers for each position (that are divisors and multiples), and then use DFS to try each possible arrangement.
I'm not sure about the complexity. 

\paragraph{527}
Try all possible abbreviations. Store the all abbreviations in a dictionary: key is the abbreviation and the value is a list
containing all the indices of the words in the input whose abbreviation is the key. When the length of a key is larger than 
one, we try to increase the prefix. Try all the prefix and when the key is uniquely used, add it into answer list.


\paragraph{529}
Reveal the current cell if it is an unrevealed mine.
Otherwise, check its neighbors (at most 8) and if there is no mine then update it according to the rule and recursively do this for its neighbors; if there is mine as its neighbor, then count the number and update current cell as number.

\paragraph{530}
Collect all the values into a set, and then transform that into a list.
Sort the list and then check each two adjacent values to find the minimum absolute difference. 
The running time is $O(n \log n)$.
My first try is to enumerate all pairs without sorting, which gives a TLE.

\paragraph{531}
First count the numbers of 'B' for each column and each row. Then use this information to count the target 'B'.
Running time $O(n^2)$.


\paragraph{532}
Store the numbers in a dictionary and count their frequency so we can easily check if the target is in the list. 
Then store the result pairs in a set and return the length of the set. Take care of the corner cases when $k = 0$ 
and $k$ is negtive.
Running time is $O(n)$.


\paragraph{533}
First count the number of 'B' for each column and each row. Then compare each pair of rows and count the number of same rows
for each row. With these information, we can check for each column with $N$ 'B's if there are $N$ same rows with 'B' in that 
column. 
Running time is $O(n^3)$ where $n$ is the max length of the row and column. If we transfer each row into a string and use hash to count the number of same strings, the running time could be $O(n^2)$.

\paragraph{536}
add the first number in the root, and then parse the string to find the next two strings for the subtrees. To parse the 
string, just count the number of parenthesis: when the numbers are equal, the parse is done. Recursively solve the substrings.

\paragraph{537}
Simulate the computation.

\paragraph{538}
Traverse the tree to collect all values in the tree and sort those in dicresing order. For each value $val$, store the sum of 
all values larger than $val$ in the dictionary indexed by $val$. Update the values in the tree by this dictionary.
Running time is $O(n \log n)$.

\paragraph{539}
Convert the time into a integer, then sort the list and compare the adjacent two numbers. Don't forget to comopare the first
and the last number. The distance between two numbers is the min of the absolute difference and 1440 - the abs difference.

\paragraph{541}
Just reverse the required substrings.

\paragraph{542}
Breadth first search for the distance. Running time is $O(n)$.

\paragraph{543}
Traverse the tree and return the longest distance in the current subtree and the lenght of the deepest path in current subtree. The answer is the maximum of the two values of the root.

\paragraph{544}
First construct the sequence of the numbers iteratively, and then convert the numbers into strings recersively.
First compute the number of roundes, which is the exponent of 2 for $n$. To construct the numbers, for the $i$th round, we start from last sequence of numbers $S^i$. For each number $x$ in $S^i$, we add $x$ and a new number $2^i+1 - x$ after $x$.
The new sequence $S^{i+1}$ has length twice as $S^i$. The base case is $i = 0$, where $S^0 = \{ 1 \}$.
After the construction, we recersively combine the numbers into strings. Each time we divide the sequence into two halves 
and then combine the strings from the two subsequences into a new string. The base case is when there are only two numbers.
The running time is $O(n)$.

\paragraph{545}
Search each boundary and then follow the rules to combine them. Take care of the corner cases.

\paragraph{546}
Dynamic programming. The state $dp[i][j][k]$ stores the max points we can get from $i$th boxes to $j$th boxes (both inclusive) 
with additional $k$ boxes of the same value as the $j$th box on the right of the $j$th box. For example, dp[1][3][2] 
is the max points from the state $\{b_1, b_2, b_3, X, X \}$ where $X = b_3$. 
The transformation is $dp[i][j][k] = \max \{dp[i][x][k+1] + dp[x+1][j-1][0], dp[i][j][k] \}$ where $boxes[x] == boxes[j]$.
If there is no such $x$, then $dp[i][j][k] = dp[i][j-1][0] + (k+1)^2$.
The running time is $O(n^4)$. 
To pass all the tests, we also need some optimization. That is, when there are consecutive same values, we want to choose $x$
as the left index, instead of trying every position. But when there are not consecutive intervals, we still need to try each 
of them.

\paragraph{547}
Union-find sets. Scan the input graph and union two friend sets. Return the number of final sets. We use the minimum number
in the set as its representative. 


\paragraph{548}
Divide and conquer. Enumerate each possible index $j$. For each $j$, split the array into two parts. For each such part, 
enumerate the split index and store the sum if the two subarray have the same sum. When there exists a stored value 
from both parts, return true, otherwise false.
Running time $O(n^2)$ since for each $j$, the computation can be done in linear time.


\paragraph{549}
Dynamic programming on tree. The state is a tuple of three lengths: the longest consecutive path less or equal to the root 
value, the longest consecutive path greater or equal to the root value, and the longest consecutive path in the subtrees 
without current root. The running time is linear.

\paragraph{551}
For 'A', we count the number; for 'L', we check if there is a substring of 'LLL'. This can be done in linear time.

\paragraph{552}
There are two methods.
\begin{itemize}
\item First, this could be solved by dynamic programming. Let $d[i]$ be the number of possible rewardable records that do not contain 'A' and
have length $i$. Then the recurrsive transformation is $d[i] = d[i-1] + d[i-2] + d[i-3]$, which means the records of length $i$
can be obtained by adding 'P', 'PL' or 'PLL' at the end of a record of length $i-1$, $i-2$ or $i-3$ respectively.
After that, we just need to count the number of records that contains one 'A', which is the sum of $d[i] * d[n-i-1]$ for all
$i>=0$. The running time is $O(n)$. 

\item This could also be solved by using matrix multiplication. We define a vector $f[i][j][k]$ that stores the number of 
rewardable records that have length $i$ and have exactly $j$ of 'A' and $k$ of 'L' at the end. Then we can find the following
relation: $f[i] = A * f[i-1]$, where $A$ is the matrix:
\[A=\left[ 
\begin{array}{cccccc}
1 & 1 & 1 & 0 & 0 & 0 \\ 
1 & 0 & 0 & 0 & 0 & 0 \\ 
0 & 1 & 0 & 0 & 0 & 0 \\
1 & 1 & 1 & 1 & 1 & 1 \\
0 & 0 & 0 & 1 & 0 & 0 \\
0 & 0 & 0 & 0 & 1 & 0 \\
\end{array} \right]. \]
Then we can compute the final vector $f[n]$ by using fast exponentiation by squaring. The running time is $O(\log n)$.
\end{itemize}


\paragraph{553}
There are two ways to solve this problem. One is to enumerate all the possible expressions and find the best, and the other
is to prove the best express always has the same form. We will show both methods.
\begin{itemize}
\item First, we show enumeration method. The idea is divide and conquer. We enumerate the position (that is the index of the array) 
$i$ to divide the array into two parts and compute the possible
max and min results of the two parts. Then we can obtain the possible max and min results of the whole array. Now we only need
to care about how to add parenthesis. We can store the expression string for the results of two subarrays and combine them 
to obtain the expression string of results of the whole array. Assume the position $i$ is not the last one. Then there are
division after this position that are operated before the division at $i$. So we need to add parenthesis to the right part of
$i$. If $i$ is the last one position, then we don't need to add parenthesis. The running time for this will be $O(n!)$, which
could be improved by memorization into $O(n^3)$.

\item The second method is to prove the best expression should always be the form $a / (b / c / d / \dots / z)$.
The proof is by induction. The hypothesis assumption is that for $k>2$ numbers, the max expression is $a_0 / (a_1 / a_2 / \dots
/ a_{k-1})$ and the min expression is $a_0 / a_1 / a_2 / \dots / a_{k-1}$.
The base case is when $k = 3$. For any $k+1$ numbers, suppose the assumption is correct for any $x <= k$ numbers. Now consider the
position $i$ for the last division operation. No matter where $i$ is, the left part has the max form and the right part has the 
min form, which can be combined into the max form of the whole sequence. Q.E.D.
\end{itemize}


\paragraph{554}
If the line crosses least bricks, then that is where most lines can be split. That is, we want to find a number that can split
most rows. For each row, the number is the sum of the bricks on the left of the line. We count such sums for all rows in 
a dictionary and choose the max value. The running time is linear to the number of bricks.

\paragraph{555}
We enumerate each possible position as the cut point and then choose the best among them as result. 
First we need to preprocess the strings so that each string is the max between its current order and its reverse order.
This is because when the cut point is not in a string $s$, it should always be chosen in the order that forms a larger string.
For the string that contains the cut point, we try all cut points in the two orders. The running time is $O(n^2)$. 

\paragraph{556}
Similar to find the next permutation. Transform the number into a list of digits. 
Find the longest increasing sequence from the end and then process this sequence.
Assume this sequence is $A[i:]$, then find the smallest element $A[j]$ in this sequence that is larger than $A[i-1]$ and swap
them. Next, sort $A[i:]$ and transform the list back to the number. Take care of the corner case.

\paragraph{557}
String processing. Split the intput into words, reverse the words and then join them by space.

\paragraph{560}
This can be solved by hashmap. For each index $i$, we could have a sum, denoted by $s_i$ for the previous $i$ numbers. 
For each such sum, we record the number of such indices. 
That is, $index[s]$ stores the number of indices $i$ we have seen such that $s_i$ is equal to $s$.
Then for each number $x$ in the array, we just need to add the number of $index[k-x]$ to our answer.
The running time is linear to the length of the array.




\paragraph{561}
Sort the array and then sum the numbers with even indices, since these will be the minimum of the pair. 
This runs in $O(n \log n)$ time.

\paragraph{562}
We could simply check each row, each column, each diagonal and each anti-diagonal to count the longest line. Or we could just
memory those values for each cell if there is one in it and then iteratively compute all four values for all cells and choose
the maximum of them. Both methods runs in linear time to the number of cells.

\paragraph{563}
Recursively compute the sum of the values and the tilt of the subtree rooted at current node. This runs in linear time.

\paragraph{564}
The closest palindrome could either has the same number of digits as $n$ or not. If not, then the answer is either of the form
$100 \dots 001$ or the form $99\dots99$. For example, the answer for 10 is 9, and the answer for 99 is 101. 
If they have the same number of digits, then the right part needs to be the same as the left part except for the middle one
or two digits. This make sure the change is minimized. For the middle one or two digits, we just need to check +1, -1 and
itself (if two digits then check the left and assign the right the same value), since other change will increase the absolute 
difference. We collect all possible values and then choose from these the nearest one as result. 
The running time is linear to the length of the given number.

\paragraph{565}
Each number in the array will be in a cycle, since its in-degree and out-degree will be one. So we store a list of boolean 
value to denote if the corresponding number is seen before. We go through the list and for each unseen number, we follow the 
cycle to set the corresponding boolean value to be true and record the size of the cycle. The answer will be the size of the 
largest cycle. THe running time is linear. 

\paragraph{566}
We can copy the elements from the given matrix to the resulting matrix. An interesting way to do this is using $i/c$ and $i \%
c$ for $0 \le i \le r * c$. The running time is linear to the number of elements.

\paragraph{567}
This problem can be solved by sliding window or two pointers.
To check the permutation, we only need to count the number of each letters in a given substring, which can be represented by an 
counting array of length 26.
For sliding window, we try each substring in $s2$ to see if the counting array is the same as that of $s1$.
For each sliding or movement of the index, we only need to change the counting array for the first letter and end letter, which
can be done in constant time.
For two pointers $start$ and $end$, we make sure the substring of $(start, end]$ contains the same letters as $s1$. So when the 
distance between the two pointers is the same as the length of $s1$, we find the right substring. To make sure the invariant, 
we do similar thing as sliding window. First find the counting array for $s1$. Then we check the new letter at index $end$: if
there are more such letter in $s1$ then our current substring, then we subtract 1 for this letter in the counting array; else
we move the $start$ index forward until we find a letter the same as $end$.
Now $end$ can move again.
The running time is linear to the length of $s2$ since the two methods just remove the two index positions in $s2$.

\paragraph{568}
This probelm can be solved by dynamic programming.
We use $dp[i][j]$ to store the max number of vacation days we can obtain in first $i-1$ weeks and ending at the $j$-th city.
Then we have $dp[i][j] = \max_{flights[x][j] == 1 || x == j} \{ dp[i][j], dp[i-1][x] + days[j][i] \}$. 
That is, we can try all possible ways to reach $j$-th city and get the max number of vacation days.
The running time is $O(n^2 k)$.

\paragraph{572}
There are two ways to solve this problem. The first is to compare $t$ with each subtree of $s$ recursively, which needs $O(mn)$ time for $n = |s|$ and $m = |t|$. The second is to convert the tree into a different representation. It could be a
string that represent the tree as Leetcode uses, or a hash function that maps each node to a distinct value according to its
subtree. This could be done in linear time and the comparison can be done in linear time by some advaced algorithm, like KMP 
for finding the substring. So the total running time is $O(m + n)$.

\paragraph{573}
This is a math problem. The answer must be a tour that the squirrel visits one nut and go to the tree, and after that it just 
go to each nut and back to the tree. So we only need to find the first nut it should visit. The distance of the tour can be 
seen as twice of the sum of the distances between all nuts and the tree minus the difference between the distance from the first nut to the tree and plus that from the first nut to the squirrel. So we can try each nut to find the minimum tour.



\paragraph{575}
We only need to compare the totall number of candies and the total number of kinds. If the number of kinds is greater than 
half of the number of candies, then there is no way to distribute all the kinds to sister. So the answer for this case is 
just half of the number of candies. Otherwise, there is always a way to give all kinds of candies to sister, so the answer is
the number of kinds.

\paragraph{576}
For each movement, we can record the number of paths to each cell. This can be done by keeping another empty matrix and 
for each cell, we record the sum of the numbers in its neighbors. And then replace the original matrix with this new matrix.
Each time we also collect the numbers in the cells outside of the 
boundary and add them into the answer variable. This is similar to the computation of the Game of Life.

\paragraph{581}
We can store the sorted list in another list $A$ and then find the first and last elements in $A$ that are different from the 
given list, this is the endpoints of the wanted subsequence. If there is no such elements, then the given list is sorted and 
we need to return 0.

\paragraph{582}
We can build the tree directly by dictionary and then search the tree from the given point and store all the visited nodes.
The running time is linear.

\paragraph{583}
This problem is the simplified version of Edit Distance and can be solved by dynamic programming. Let $dp[i][j]$ denote the 
minimum number of deletions needed to make $word1[:i]$ and $word2[:j]$ the same. Then $dp[i][j] = \min \{ dp[i-1][j], 
dp[i][j-1] \} + 1$ if $word1[i] != word2[j]$ and $dp[i][j] = dp[i-1][j-1]$ if $word1[i] == word2[j]$. 
The running time is $mn$ for $m$ and $n$ being the lengths of two words.

\paragraph{587}
Just need to compute the convex hull of the given points.

\paragraph{588}
We can construct a tree as the file system, where each node is either a file or a directory. 
A node consists of a name, a list of children and a string as content. 
Then each operation is transformed into the operation in the tree. 
To speedup the reading operation, we can store the path of a file and its content into a dictionary.
Thus, the reading only needs constant time. 

\paragraph{591}
We can either solve this problem by DFA (deterministic finite automaton). 
We have totally 4 kinds of states, 0: start tag, 1: end tag, 2: text, 3: cdata.
We go through the input with index $i$ starting from $i=1$ (If input is an empty string, return false) and state = 0.
We also have a stack to store the previous unmatched tag word.
For each state, we check if the condition is satisfied and transfer to the next state according to the input string.
Since we only need to go through the input once, the running time is linear.
It seems that this can also be solved by regular expression, but I'm not sure.

\paragraph{592}
We can have two integers denote the numerator and denominator of the result. And then just extract the next fraction and add
it to our result. This can be done in linear time. 

\paragraph{593}
We can compute the distance between each pair of points and then store them in a counter. If the points can form a square 
the, there should only be two distances in the counter such that one repeats twice and the other repeats four times.
This can be done in constant time.


\paragraph{594}
We can count the number of each elements in the list by a dictionary and then for each element $i$, we check if $i+1$ is in 
our counter and output the max sum of the counts of such $i$ and $i+1$. The running time is linear.

\paragraph{598}
Note that the operation will always be addition for a rectangle whose left index and top index are both 0. So we only need to 
find the common area of all the operations. That is, we only need to find the two minimum indices for the operations. So the 
running time is linear. 


\paragraph{599}
We can store the name and its index in list2 in a dictionary first. And then we go through list1 and check if the index sum is
better then current sum. If better, we replace current answer with a new list with the current name. If equal, then we add the 
current name into our answer list. The running time is linear.

\paragraph{600}
This problem can be solved by dynamic programming. Let $dp[i][0]$ and $dp[i][1]$ denote the number of non-negative integers 
whose binary representations do not contain consecutive ones and have length at most $i$ and the leftmost bit is 0 or 1
respectively. Then the recursive relation is $dp[i][0] = dp[i-1][0] + dp[i-1][1]$ and $dp[i][1] = dp[i-1][0]$. Assume the 
length of the binary representation is $n$. Then we compute $dp[i]$ for $0 <= i <= n$. Now we start from the leftmost bit and 
check if the bit is '1' and if its previous bit is '1'. If the current bit is '1' and the previous is not '1', we add 
$dp[n-i][0]$ into our answer. This means we fix the previous bits and set the current bit to '0' and count the number of 
integers. If we find the current bit and privous bit are both '1', then we do this counting for the current bit and then stop
this process since the later numbers will always contain consecutive ones.
We also need to add 1 to our answer if there is no '11' in the given number, which means we need to count the given number in
our answer. The running time is $O(\log n)$.
We can also use $dp[i]$ to represent $dp[i][0]$, since then $dp[i][1]$ will become $dp[i-1]$. 

\paragraph{604}
We store the given string, the current index and the left count for the current letter in the class.
For hasNext function, we check if the current index is out of the given string, and also check if the index should move 
forward by checking if the count is 0. If count is 0, then we need to compute the number of this letter. 
For next function, we first check hasNext. If true, then we decrese the count and move the current if the count is 0.
Then we output the letter.
The average case complexity for both functions is $O(1)$. The worst case complexity for both is $O(n)$ where $n$ is the length
of the given string. 


\paragraph{605}
We can go through the list and check if each position satisfies the condition. If so, we change it to 1 and continue.
This can be done in lienar time.

\paragraph{606)
We can visit each node recursively and return the string for the subtree rooted at the node. If the node is a leaf, we don't 
add any more parenthesis pair. This can be done in linear time.

\paragraph{609}
We only need to sparse the input strings to find the directory, the file name, and the content. And then we store the path, 
which consists of the directory and the file name, in a dictionary, indexed by the content. That is, the value for each 
content is a list containing all the paths for the duplicate files with that content.
Then we return the lists whose lengths are greater than one. The running time is linear.

\paragraph{611}
The problem define that the same value appear at different places are different. And the tuple does not have order.
We will solve this problem by three ``pointers''. First we sort the list.
Our first pointer $i$ go through the list and indicates the largest value in the 
tuple. This is the first loop. Inside of this loop. we set two pointers for the two samller values in the tuple: $l$ is the 
pointer for the smallest value and starts at 0; $r$ is the pointer for the middle value and starts at $i-1$.
If the triangle condition $nums[l] + nums[r] > nums[i]$ is satisfied, then we add $r-l$ to our answer and decrease $r$ by 1; 
otherwise we increase $l$ by 1. When the two points meet, we stop this process and increase $i$ by 1.
The running time is $O(n^2)$.
We can also set the first pointer for the smallest value and the other two for the larger values. Then the dicrection of 
movement is different but the running time is still $O(n^2)$.


\paragraph{616}
We maintain a bool list of the same size as the input list such that if the element is true if the corresponding element in
the given array is in a bold tag. Then we just need to construct this bool list. We go through the given list and for each 
index, we try each word in the dictionary to see if there is a word that starts at this index. If so, choose the longest one 
and set the corresponding elements true. After that, we just need to construct the anwser string according to the two lists.
We can do this by setting a bool flag which shows if we are in the tag or not and adding tags according the flag.
Another way to solve this problem is by trie. First we construct the trie from the dictionary and then search the trie for 
each index of the given string.

\paragraph{617}
We traverse the two trees at the same time and combine the values if they are both not None. If one of them is None, then we 
ignore it and follow the other tree; if both are None, we return None.
The running time is linear to the sum of the sizes of the trees.



\end{document}
